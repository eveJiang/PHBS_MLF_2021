{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #3: PCA/Hyperparameter/CV\n",
    "Data source: http://archive.ics.uci.edu/ml/datasets/Polish+companies+bankruptcy+data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = arff.loadarff('4year.arff')\n",
    "df = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bankruptcy'] = (df['class']==b'1')\n",
    "df.drop(columns=['class'], inplace=True)\n",
    "df.columns = ['X{0:02d}'.format(k) for k in range(1,65)] + ['bankruptcy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X01</th>\n",
       "      <th>X02</th>\n",
       "      <th>X03</th>\n",
       "      <th>X04</th>\n",
       "      <th>X05</th>\n",
       "      <th>X06</th>\n",
       "      <th>X07</th>\n",
       "      <th>X08</th>\n",
       "      <th>X09</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X55</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9749.000000</td>\n",
       "      <td>9.771000e+03</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9773.000000</td>\n",
       "      <td>9792.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.792000e+03</td>\n",
       "      <td>9771.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9776.000000</td>\n",
       "      <td>9791.000000</td>\n",
       "      <td>9178.000000</td>\n",
       "      <td>9760.000000</td>\n",
       "      <td>9.771000e+03</td>\n",
       "      <td>9749.000000</td>\n",
       "      <td>9561.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.043019</td>\n",
       "      <td>0.596404</td>\n",
       "      <td>0.130959</td>\n",
       "      <td>8.136600</td>\n",
       "      <td>6.465164e+01</td>\n",
       "      <td>-0.059273</td>\n",
       "      <td>0.059446</td>\n",
       "      <td>19.884016</td>\n",
       "      <td>1.882296</td>\n",
       "      <td>0.389040</td>\n",
       "      <td>...</td>\n",
       "      <td>7.686330e+03</td>\n",
       "      <td>-0.992263</td>\n",
       "      <td>0.035022</td>\n",
       "      <td>1.133287</td>\n",
       "      <td>0.856053</td>\n",
       "      <td>118.156064</td>\n",
       "      <td>25.194430</td>\n",
       "      <td>2.015157e+03</td>\n",
       "      <td>8.660813</td>\n",
       "      <td>35.949619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.359321</td>\n",
       "      <td>4.587122</td>\n",
       "      <td>4.559074</td>\n",
       "      <td>290.647281</td>\n",
       "      <td>1.475939e+04</td>\n",
       "      <td>6.812754</td>\n",
       "      <td>0.533344</td>\n",
       "      <td>698.697015</td>\n",
       "      <td>17.674650</td>\n",
       "      <td>4.590299</td>\n",
       "      <td>...</td>\n",
       "      <td>7.605261e+04</td>\n",
       "      <td>77.007971</td>\n",
       "      <td>8.945365</td>\n",
       "      <td>8.038201</td>\n",
       "      <td>26.393305</td>\n",
       "      <td>3230.316692</td>\n",
       "      <td>1099.260821</td>\n",
       "      <td>1.171461e+05</td>\n",
       "      <td>60.838202</td>\n",
       "      <td>483.318623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-12.458000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-445.910000</td>\n",
       "      <td>-0.045319</td>\n",
       "      <td>-3.794600e+05</td>\n",
       "      <td>-486.820000</td>\n",
       "      <td>-12.458000</td>\n",
       "      <td>-1.848200</td>\n",
       "      <td>-0.032371</td>\n",
       "      <td>-445.910000</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.132200e+05</td>\n",
       "      <td>-7522.100000</td>\n",
       "      <td>-597.420000</td>\n",
       "      <td>-30.892000</td>\n",
       "      <td>-284.380000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-12.656000</td>\n",
       "      <td>-1.496500e+04</td>\n",
       "      <td>-0.024390</td>\n",
       "      <td>-0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.263145</td>\n",
       "      <td>0.020377</td>\n",
       "      <td>1.047000</td>\n",
       "      <td>-5.121700e+01</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.428300</td>\n",
       "      <td>1.006675</td>\n",
       "      <td>0.294440</td>\n",
       "      <td>...</td>\n",
       "      <td>2.184000e+01</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.008768</td>\n",
       "      <td>0.885722</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.356325</td>\n",
       "      <td>4.267700</td>\n",
       "      <td>4.323400e+01</td>\n",
       "      <td>2.938800</td>\n",
       "      <td>2.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.041364</td>\n",
       "      <td>0.467740</td>\n",
       "      <td>0.199290</td>\n",
       "      <td>1.591800</td>\n",
       "      <td>-5.557600e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048820</td>\n",
       "      <td>1.088700</td>\n",
       "      <td>1.161300</td>\n",
       "      <td>0.510450</td>\n",
       "      <td>...</td>\n",
       "      <td>9.503300e+02</td>\n",
       "      <td>0.043679</td>\n",
       "      <td>0.098026</td>\n",
       "      <td>0.958305</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>9.482000</td>\n",
       "      <td>6.283550</td>\n",
       "      <td>7.472900e+01</td>\n",
       "      <td>4.848900</td>\n",
       "      <td>4.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.111130</td>\n",
       "      <td>0.689255</td>\n",
       "      <td>0.410670</td>\n",
       "      <td>2.880400</td>\n",
       "      <td>5.573200e+01</td>\n",
       "      <td>0.065322</td>\n",
       "      <td>0.126940</td>\n",
       "      <td>2.691000</td>\n",
       "      <td>1.970225</td>\n",
       "      <td>0.714290</td>\n",
       "      <td>...</td>\n",
       "      <td>4.694550e+03</td>\n",
       "      <td>0.117170</td>\n",
       "      <td>0.242680</td>\n",
       "      <td>0.996163</td>\n",
       "      <td>0.211790</td>\n",
       "      <td>19.506000</td>\n",
       "      <td>9.938200</td>\n",
       "      <td>1.233450e+02</td>\n",
       "      <td>8.363800</td>\n",
       "      <td>9.413500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.482000</td>\n",
       "      <td>446.910000</td>\n",
       "      <td>22.769000</td>\n",
       "      <td>27146.000000</td>\n",
       "      <td>1.034100e+06</td>\n",
       "      <td>322.200000</td>\n",
       "      <td>38.618000</td>\n",
       "      <td>53209.000000</td>\n",
       "      <td>1704.800000</td>\n",
       "      <td>12.602000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.123700e+06</td>\n",
       "      <td>112.020000</td>\n",
       "      <td>226.760000</td>\n",
       "      <td>668.750000</td>\n",
       "      <td>1661.000000</td>\n",
       "      <td>251570.000000</td>\n",
       "      <td>108000.000000</td>\n",
       "      <td>1.077900e+07</td>\n",
       "      <td>5662.400000</td>\n",
       "      <td>21153.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               X01          X02          X03           X04           X05  \\\n",
       "count  9791.000000  9791.000000  9791.000000   9749.000000  9.771000e+03   \n",
       "mean      0.043019     0.596404     0.130959      8.136600  6.465164e+01   \n",
       "std       0.359321     4.587122     4.559074    290.647281  1.475939e+04   \n",
       "min     -12.458000     0.000000  -445.910000     -0.045319 -3.794600e+05   \n",
       "25%       0.001321     0.263145     0.020377      1.047000 -5.121700e+01   \n",
       "50%       0.041364     0.467740     0.199290      1.591800 -5.557600e-02   \n",
       "75%       0.111130     0.689255     0.410670      2.880400  5.573200e+01   \n",
       "max      20.482000   446.910000    22.769000  27146.000000  1.034100e+06   \n",
       "\n",
       "               X06          X07           X08          X09          X10  ...  \\\n",
       "count  9791.000000  9791.000000   9773.000000  9792.000000  9791.000000  ...   \n",
       "mean     -0.059273     0.059446     19.884016     1.882296     0.389040  ...   \n",
       "std       6.812754     0.533344    698.697015    17.674650     4.590299  ...   \n",
       "min    -486.820000   -12.458000     -1.848200    -0.032371  -445.910000  ...   \n",
       "25%      -0.000578     0.003004      0.428300     1.006675     0.294440  ...   \n",
       "50%       0.000000     0.048820      1.088700     1.161300     0.510450  ...   \n",
       "75%       0.065322     0.126940      2.691000     1.970225     0.714290  ...   \n",
       "max     322.200000    38.618000  53209.000000  1704.800000    12.602000  ...   \n",
       "\n",
       "                X55          X56          X57          X58          X59  \\\n",
       "count  9.792000e+03  9771.000000  9791.000000  9776.000000  9791.000000   \n",
       "mean   7.686330e+03    -0.992263     0.035022     1.133287     0.856053   \n",
       "std    7.605261e+04    77.007971     8.945365     8.038201    26.393305   \n",
       "min   -7.132200e+05 -7522.100000  -597.420000   -30.892000  -284.380000   \n",
       "25%    2.184000e+01     0.003121     0.008768     0.885722     0.000000   \n",
       "50%    9.503300e+02     0.043679     0.098026     0.958305     0.002129   \n",
       "75%    4.694550e+03     0.117170     0.242680     0.996163     0.211790   \n",
       "max    6.123700e+06   112.020000   226.760000   668.750000  1661.000000   \n",
       "\n",
       "                 X60            X61           X62          X63           X64  \n",
       "count    9178.000000    9760.000000  9.771000e+03  9749.000000   9561.000000  \n",
       "mean      118.156064      25.194430  2.015157e+03     8.660813     35.949619  \n",
       "std      3230.316692    1099.260821  1.171461e+05    60.838202    483.318623  \n",
       "min         0.000000     -12.656000 -1.496500e+04    -0.024390     -0.000015  \n",
       "25%         5.356325       4.267700  4.323400e+01     2.938800      2.012900  \n",
       "50%         9.482000       6.283550  7.472900e+01     4.848900      4.041600  \n",
       "75%        19.506000       9.938200  1.233450e+02     8.363800      9.413500  \n",
       "max    251570.000000  108000.000000  1.077900e+07  5662.400000  21153.000000  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "515"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.bankruptcy == True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(df.mean(), inplace=True)\n",
    "df.isna().sum()\n",
    "X_imp = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = X_imp[:, :-1], X_imp[:, -1]\n",
    "y = y.astype(bool)\n",
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6854, 64)\n",
      "(2938, 64)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as skpre\n",
    "\n",
    "stdsc = skpre.StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "print(X_train_std.shape)\n",
    "X_test_std = stdsc.transform(X_test)\n",
    "print(X_test_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) LR pipeline\n",
    "hyper-parameter:\n",
    "1. C: np.logspace(-6,6,100)\n",
    "2. penalty: \"none\", \"l1\", \"l2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) LR with penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "{'C': 0.07054802310718646, 'penalty': 'l2'} 0.1791703442188879 0.7286256200758681 0.17995910020449898 0.7270251872021783\n"
     ]
    }
   ],
   "source": [
    "pipe_lr = make_pipeline(\n",
    "    PCA(n_components=3),\n",
    "    GridSearchCV( # grid search for hyper-parameters\n",
    "        LogisticRegression(\n",
    "            solver='liblinear',\n",
    "            class_weight='balanced',\n",
    "            random_state=1,\n",
    "        ), \n",
    "        param_grid={\n",
    "            'C': np.logspace(-6,6,100),\n",
    "            \"penalty\": [\"l1\", \"l2\"]\n",
    "        }, \n",
    "        cv=5, # 5 fold Cross-Validation\n",
    "        scoring='f1',\n",
    "        verbose=1\n",
    "    )\n",
    ")\n",
    "\n",
    "pipe_lr.fit(X_train_std, y_train)\n",
    "param_best = pipe_lr.steps[1][1].best_params_\n",
    "y_train_pred = pipe_lr.predict(X_train_std)\n",
    "y_test_pred = pipe_lr.predict(X_test_std)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "acc_test = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(\n",
    "    param_best,\n",
    "    f1_train,\n",
    "    acc_train,\n",
    "    f1_test,\n",
    "    acc_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) SVM pipeline\n",
    "hyper-parameter:\n",
    "1. C: np.logspace(-2,2,4)\n",
    "2. gamma: np.logspace(-2,2,4) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "0.18621307072515664 0.7347534286548001 0.1873684210526316 0.7372362151123213\n"
     ]
    }
   ],
   "source": [
    "pipe_svm = make_pipeline(\n",
    "    PCA(n_components=3),\n",
    "    GridSearchCV(\n",
    "        SVC(\n",
    "            kernel='rbf', \n",
    "            tol=1e-2,\n",
    "            class_weight='balanced',\n",
    "            random_state=1,\n",
    "        ), \n",
    "        param_grid={\n",
    "            'C': np.logspace(-2,2,4),\n",
    "            'gamma': np.logspace(-2,2,4) * 0.5,\n",
    "        }, \n",
    "        cv=5, \n",
    "        scoring='f1',\n",
    "        verbose=1\n",
    "    )\n",
    ")\n",
    "\n",
    "pipe_svm.fit(X_train_std, y_train)\n",
    "param_best = pipe_svm.steps[1][1].best_params_\n",
    "y_train_pred = pipe_svm.predict(X_train_std)\n",
    "y_test_pred = pipe_svm.predict(X_test_std)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "acc_test = accuracy_score(y_test, y_test_pred)\n",
    "print(\n",
    "    f1_train,\n",
    "    acc_train,\n",
    "    f1_test,\n",
    "    acc_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Decision Tree pipeline\n",
    "hyper-parameter:\n",
    "1. criterion: [\"gini\", \"entropy\"]\n",
    "2. max_depth: range(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "{'criterion': 'gini', 'max_depth': 3} 0.20150501672240803 0.7213306098628538 0.18725099601593623 0.7222600408441117\n"
     ]
    }
   ],
   "source": [
    "pipe_tree = make_pipeline(\n",
    "    PCA(n_components=3),\n",
    "    GridSearchCV(\n",
    "        DecisionTreeClassifier(\n",
    "            class_weight='balanced',\n",
    "            random_state=1,\n",
    "        ), \n",
    "        param_grid={\n",
    "            \"criterion\": [\"gini\", \"entropy\"],\n",
    "            \"max_depth\": range(1, 10)\n",
    "        }, \n",
    "        cv=5, \n",
    "        scoring='f1',\n",
    "        verbose=1\n",
    "    )\n",
    ")\n",
    "\n",
    "pipe_tree.fit(X_train_std, y_train)\n",
    "param_best = pipe_tree.steps[1][1].best_params_\n",
    "y_train_pred = pipe_tree.predict(X_train_std)\n",
    "y_test_pred = pipe_tree.predict(X_test_std)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "acc_train = accuracy_score(y_train, y_train_pred)\n",
    "acc_test = accuracy_score(y_test, y_test_pred)\n",
    "print(\n",
    "    param_best,\n",
    "    f1_train,\n",
    "    acc_train,\n",
    "    f1_test,\n",
    "    acc_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
